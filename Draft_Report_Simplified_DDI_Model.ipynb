{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YROt7YuUk7cF"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "##### Problem Background\n",
        "\n",
        "\n",
        "When multiple drugs are used in treatment of a patient, there is a possibility drugs interact, potentially causing harmful effects.\n",
        "To reduce drug development time and uncover negative interactions before human trials, clinicians need a way to predict these drug interactions. This problem is combinatorially difficult due to the massive number of drugs, variations in drug features such as molecular structure, and the range of potential interactions. By using neural networks, clinicians could uncover patterns in drug interaction, enabling better understanding of drug functionality on the body. This understanding could not only discover negative drug interactions, but also secondary use-cases of drugs for treatment.\n",
        "\n",
        "\n",
        "Traditional model architectures, such as proposed by $Rohani^{1}$ utilize drug-similarity matrices of features such as molecular substructure to predict interactions. These matrices are sub-selected for the most informative and fused into a singular matrix as input for a neural network. These approaches omit critical information about the kind of interactions between drugs, and simply discover any interaction. For clinicians to properly understand drug functionality and safety of use, they must be able to predict the severity and type of drug interactions.\n",
        "\n",
        "\n",
        "Graph Neural Networks have recently been employed to encode and explore various drug interaction types. By encoding drugs as nodes, and interaction types as edges, models can better understand how drugs interact with one another. However, generating graph representations of drug interactions is challenging, particularly in how to combine various features from various sources and how to generate embeddings. $Lin et al^{2}$, generates a graph structure from various features, but only predicts the presence of an interaction from node locality - ignoring the semantic representation of features.\n",
        "\n",
        "\n",
        "##### Paper Explanation\n",
        "\n",
        "$Al-Rabeah^{3}$ improves upon both the traditional and GNN approaches by utilizing graph networks of various features to generate embeddings for feeding into a neural network for classification. The aim is to integrate both the similarity matrices of previous approaches with GNN embeddings of multiple featuresets, in order to represent a heterogeneous network for predicting the types of drug-drug interactions.\n",
        "\n",
        "\n",
        "The work utilizes four feature matrices (Chemical structure, Target, Enzyme, and Pathway) as attributes for nodes representing drugs via similarity matrices, with edges being the drug-drug interaction. A graph is constructed for each feature matrix, and each graph is then used to generate an embedding matrix with a vector for each drug and interaction type. This is done via a random walk from the drug node utilizing edges of the given interaction type to form a node sequence, which is then used to learn embeddings. For each drug pair, the drug embedding vectors are element-wise multiplied with each other to represent drug-drug pairs. These vectors are then fed into the corresponding neural network, one for each graph, using a softmax to generate a probability vector over all event types. These probabilities are then averaged to produce a final prediction vector.\n",
        "\n",
        "\n",
        "The work tested using all subsets of the feature matrices, with the best performance from using all four matrices gathered. The results, achieving 0.9206, 0.9992, 0.9717, 0.8579, and 0.8259 Accuracy, AUC, AUPR, F1, and recall scores respectively, outperformed many recent DDI works. This showed significant improvement over traditional Neural Network approaches, such as CNN-DDI by $Zhang^{4}$. While other GNN approaches, such as the novel KGNN, achieved better performance in some metrics such as F1 score - their analysis was over individual datasets and neglected several features. From this, the GNN-DDI architecture showed exceptional performance as it was faced with multiple-datasets, indicating strong usage across various features.\n",
        "\n",
        "\n",
        "The work of $Al-Rabeah^{3}$ showed the strength of combining various feature sets for generating neural network inputs. Likewise, the paper exemplified the utility in combining multiple components of past approaches (GNN and fusion of multiple similarity matrix results) to produce a robust architecture performant over features from multiple datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRin3Tu0k7cI"
      },
      "source": [
        "# Scope of Reproducibility\n",
        "\n",
        "All of our efforts, including this notebook, pre-computed models, processed data, etc. are located within [our teams Github repository](https://github.com/NealRyan/Drug-drug-interaction-modeling/blob/main). For our project, we utilized the [papers authors code repository](https://github.com/Mohammad-Hussain95/GNN_DDI/tree/main/).\n",
        "\n",
        "The original code was written in Tensorflow and was extremely hard to understand and modify, using obscure, lengthy matrix transformations to perform general operations. We first re-implemented the entire code repository of the paper using PyTorch.  By re-writing in PyTorch, we found it easier to implement various modifications/ablations within the original codebase. This is the extent of our work for the initial draft.\n",
        "\n",
        "\n",
        "With the Pytorch code, we plan to test the below hypotheses and ablations in our final report:\n",
        "\n",
        "\n",
        "1. Hyperparameter Tuning.\n",
        "   By varying the below hyperparameters, we attempt to achieve a higher performance from the model. The paper performs minimal hyperparameter tuning, so we anticipate minor tuning to significantly improve performance. In addition, the original paper uses the Adam optimizer which is relatively fast to converge on local minima. By optimizing parameters, we could achieve a better minimum for training our models.\n",
        "   - Layer size\n",
        "       - Varying the sizes of intermediary layers can constrain the model's performance to fit to training data. By reducing intermediary layer size, we can have a looser bias to the training set. This could be used to lower dropout rate, enabling faster training without sacrificing model generalization.\n",
        "   - Number of dense layers\n",
        "       - The dataset utilized by the paper is unbalanced leading to underfitting. We anticipate increasing the number of dense layers (2) within the neural networks will result in a more biased model - which could better fit the intricacies of less prevalent drug-drug interactions.\n",
        "   - Dropout rate\n",
        "       - The paper uses a dropout rate of 0.3 to inject random noise and reduce bias. By modifying dropout rate, alongside changes to layer size, we anticipate the same model generalization with improved fitting to training data.\n",
        "2. Removing Dropout, and replacing with optimizer weight decay.\n",
        "   Dropout introduces randomness into the network, while weight decay promotes a balanced model by regulating heavy weights. We anticipate weight decay to more effectively account for relations in similarity matrices, particularly for interactions less present in the training set, leading to a higher CV score.\n",
        "3. Replacing the Adam optimizer with SGD.\n",
        "   The paper did not tune the parameters of the Adam optimizer, which likely led to convergence on a suboptimal minima. SGD is less likely to converge on these minima, and should result in better generalizability than untuned Adam.\n",
        "4. Removal of dropout layers.\n",
        "   The proposed GNN relies on two hidden-layer 0.3 rate dropout layers to prevent overfitting. We will test the removal of each hidden layer, as well as both layers. By removing these layers, we can evaluate how tightly model overfits to the similarity matrices.\n",
        "5. Removal of early stopping.\n",
        "   The code utilizes early stopping to prevent model overfitting if performance doesn’t improve in 10 epochs. We will remove this limitation, and attempt to overfit our network while retaining dropout. This will help evaluate how injected noise impacts performance.\n",
        "6. Combining of 4 feedforward networks into 1.\n",
        "   The paper uses 4 feedforward networks to evaluate each property type independently and aggregates the results, however this does not capture any interactions between property types. We will test concatenating the feature vectors from each property type and using a single feedforward network with this feature vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huf0EWW7k7cI"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "Directly below we cover our data and how we processed it. Further in the notebook (near the relevant code cells) we explain our models, model training, and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKUA6cLJk7cJ"
      },
      "source": [
        "## Data\n",
        "\n",
        "### Data Descriptions\n",
        "\n",
        "The paper utilizes four 2-D feature matrices of 572 drugs, derived from different databases:\n",
        "* Chemical Structure\n",
        "   - SMILE strings, ASCII representations, of drug molecule structures. Commonly used to encode molecular structure.\n",
        "* Target\n",
        "   - The molecule in the body which drug is intended to impact.\n",
        "* Enzyme\n",
        "   - The enzyme responsible for processing a drug within the body. Enzymes can degrade molecules into derivatives.\n",
        "* Pathway\n",
        "   - The specific pathway through which drugs are absorbed, distributed, metabolized, and excreted from the body.\n",
        "\n",
        "All feature matrices were derived from the DrugBank database, and sourced from $Deng et al^{5}$ as an _eventdb_. The Pathway feature matrix also includes data from the KEGG database. Each row in the matrices represents an individual drug, while the columns are 1-hot encodings of the presence of drug properties. As a result, each matrix varies in the length of the second axis.\n",
        "\n",
        "\n",
        "To achieve a representation of drug similarity, these feature matrices are transformed into similarity matrices via a Jaccard similarity function. This results in uniform 572x572 similarity feature matrices. These similarity matrices were provided, however we also utilized our own code to derive these matrices. PCA analysis was then done on the similarity matrices, and the resulting matrices become the node attributes for our various graphs.\n",
        "\n",
        "\n",
        "In addition, the paper utilizes an interaction matrix, describing 65 types of interactions between the 572 drugs (as well as no interaction). These 65 (66 including no interaction) types are the types of DDI events extracted by $Deng et al^{5}$. This matrix is used to create the edges of our drug graphs.\n",
        "The matrix has 4 dimensions:\n",
        "- Drug 1\n",
        "- Drug 2\n",
        "   * Note, since there is no causal relationship between the drugs, Drug 1 and Drug 2 for a given row can be swapped.\n",
        "- Mechanism of drug interaction\n",
        "- If interaction is increased or decreased\n",
        "\n",
        "From this, the paper can derive two submatrices: the presence of drug interactions and interaction types. The distribution of the data is extremely uneven across event types, resulting in underfitting to the less represented events. This fact informed the basis of many of our experiments - as we try to appropriately fit the model for these events.\n",
        "\n",
        "We perform analysis over these different matrices in the below sections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwcg87xjk7cJ"
      },
      "source": [
        "# Notebook Setup\n",
        "\n",
        "* To install necessary requirements, run the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGpAL7WeoJP"
      },
      "source": [
        "##### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jO3dp-JelVC",
        "outputId": "5adf9c8a-b8e1-4174-ca37-a2cf5efdbb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
            "Requirement already satisfied: torch==2.2.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.13.1+cu121 (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.0+cu121, 0.16.1, 0.16.1+cu121, 0.16.2, 0.16.2+cu121, 0.17.0, 0.17.0+cu121, 0.17.1, 0.17.1+cu121, 0.17.2, 0.17.2+cu121)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.13.1+cu121\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt22cu121\n",
            "2.2.1+cu121\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import sqlite3\n",
        "!pip install torch==2.2.1+cu121 torchvision==0.13.1+cu121 torchaudio==0.12.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import Node2Vec\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, roc_auc_score, accuracy_score, f1_score, precision_recall_curve\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "from operator import index\n",
        "from six import iteritems\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZdTZTUk7cL"
      },
      "source": [
        "### Notebook Configuration\n",
        "\n",
        "This paper has several steps including:\n",
        "* Download event_db and extract raw drug attributes and interaction data.\n",
        "* Train GNN models and generate graph embeddings\n",
        "* Train NN\n",
        "\n",
        "For ease of running, we will enable feature_flags, selecting to either fully run each step OR download from precomputed sources. Any step can be toggled on/off in the below cell. The precomputed resources are stored in [our teams github repository](https://github.com/NealRyan/Drug-drug-interaction-modeling/tree/main).\n",
        "\n",
        "For the best performance, use precomputed data by setting flags to default values provided below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV6ezMphImS_"
      },
      "source": [
        "##### Set Control Flags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_GNN = False # default: False\n",
        "TRAIN_DNN = False # default: False\n",
        "\n",
        "USE_GIVEN_DATA = True # default: True\n",
        "\n",
        "DOWNLOAD_MODELS = False # default: False"
      ],
      "metadata": {
        "id": "Ts5-QoNAIqmI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8y8OhcxesNl"
      },
      "source": [
        "##### Download and Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR9Kva3pe5M-"
      },
      "source": [
        "##### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rknog8eeeqsS"
      },
      "outputs": [],
      "source": [
        "def download_file(url, filename):\n",
        "    response = requests.get(url)\n",
        "    with open(filename, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "def read_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip().split() for line in file.readlines()]\n",
        "\n",
        "def download_model_file(url, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(filename, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWrox_yue63e"
      },
      "source": [
        "##### Datapaths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pt62wzMee9IK"
      },
      "outputs": [],
      "source": [
        "urls = {\n",
        "    'train': 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/data5/train.txt',\n",
        "    'test' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/data5/test.txt',\n",
        "    'valid' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/data5/valid.txt',\n",
        "    'full_pos2': 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/full_pos2.txt',\n",
        "    'all_neg2': 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/all_neg2.txt',\n",
        "    'enzyme' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Similarity%20Matrices/enzyme.txt',\n",
        "    'pathway' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Similarity%20Matrices/pathway.txt',\n",
        "    'substructure' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Similarity%20Matrices/substructure.txt',\n",
        "    'target' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Similarity%20Matrices/target.txt',\n",
        "    'drugs' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Encoded%20Features%20Data/DrugList.txt',\n",
        "    'events' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Encoded%20Features%20Data/event_number.csv',\n",
        "    'enzyme_pca' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/enzyme_PCA.csv',\n",
        "    'pathway_pca' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/pathway_PCA.csv',\n",
        "    'substructure_pca' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/smile_PCA.csv',\n",
        "    'target_pca' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/target_PCA.csv',\n",
        "    'eventdb' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Raw%20Event%20DB/event.db'\n",
        "    #'walks' : 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Original%20Code/DDI/data5/walks.txt'\n",
        "}\n",
        "\n",
        "model_urls = {\n",
        "    'enzyme_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/enzyme_model_best_model.pth',\n",
        "    'pathway_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/pathway_model_best_model.pth',\n",
        "    'substructure_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/substructure_model_best_model.pth',\n",
        "    'target_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/target_model_best_model.pth',\n",
        "    'raw_data_enzyme_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/raw_data_enzyme_model_best_model.pth',\n",
        "    'raw_data_pathway_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/raw_data_pathway_model_best_model.pth',\n",
        "    'raw_data_substructure_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/raw_data_substructure_model_best_model.pth',\n",
        "    'raw_data_target_model_best_model': 'https://github.com/NealRyan/Drug-drug-interaction-modeling/raw/main/Model%20Files/raw_data_target_model_best_model.pth'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHDvB-TfIpt"
      },
      "source": [
        "##### Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "34_yu8XyfIEG"
      },
      "outputs": [],
      "source": [
        "# Download the text files\n",
        "for key, url in urls.items():\n",
        "    download_file(url, f\"{key}.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the models\n",
        "for key, url in model_urls.items():\n",
        "    download_file(url, f\"{key}.pth\")"
      ],
      "metadata": {
        "id": "eVKpDTHNQI1P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ojAJFZpk7cM"
      },
      "source": [
        "### Extract Raw Feature Data\n",
        "\n",
        "Download and extract raw feature data from event_db (from Deng et al) and convert into the required Jacard similarity matrices."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('/content/eventdb.txt')\n",
        "\n",
        "df_raw_drug = pd.read_sql('select * from drug;', conn)\n",
        "df_raw_extraction = pd.read_sql('select * from extraction;', conn)\n",
        "#df_raw_event = pd.read_sql('select * from event;', conn)\n",
        "#df_raw_event_num = pd.read_sql('select * from event_number;', conn)\n",
        "\n",
        "# close the DB connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "mR_P8odPq13E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_from_set(in_set):\n",
        "    ret_dic = {}\n",
        "    count = 0\n",
        "    for val in in_set:\n",
        "        ret_dic[val] = count\n",
        "        count += 1\n",
        "\n",
        "    return ret_dic\n",
        "\n",
        "def index_list_from_str_list(str_list, str_dict):\n",
        "    ret_list = []\n",
        "    for s in str_list:\n",
        "        ret_list.append(str_dict[s])\n",
        "\n",
        "    return ret_list\n",
        "\n",
        "targets = set()\n",
        "enzymes = set()\n",
        "pathways = set()\n",
        "smiles = set()\n",
        "\n",
        "for index, row in df_raw_drug.iterrows():\n",
        "    target_list = row['target'].split('|')\n",
        "    enzyme_list = row['enzyme'].split('|')\n",
        "    pathways_list = row['pathway'].split('|')\n",
        "    smiles_list = row['smile'].split('|')\n",
        "\n",
        "    targets.update(target_list)\n",
        "    enzymes.update(enzyme_list)\n",
        "    pathways.update(pathways_list)\n",
        "    smiles.update(smiles_list)\n",
        "\n",
        "targets_dic = dict_from_set(targets)\n",
        "enzymes_dic = dict_from_set(enzymes)\n",
        "pathways_dic = dict_from_set(pathways)\n",
        "smiles_dic = dict_from_set(smiles)\n",
        "\n",
        "targets_jac = np.zeros((len(df_raw_drug.index), len(targets)))\n",
        "enzymes_jac = np.zeros((len(df_raw_drug.index), len(enzymes)))\n",
        "pathways_jac = np.zeros((len(df_raw_drug.index), len(pathways)))\n",
        "smiles_jac = np.zeros((len(df_raw_drug.index), len(smiles)))\n",
        "\n",
        "for index, row in df_raw_drug.iterrows():\n",
        "    targets_jac[index, index_list_from_str_list(row['target'].split('|'), targets_dic)] = 1\n",
        "    enzymes_jac[index, index_list_from_str_list(row['enzyme'].split('|'), enzymes_dic)] = 1\n",
        "    pathways_jac[index, index_list_from_str_list(row['pathway'].split('|'), pathways_dic)] = 1\n",
        "    smiles_jac[index, index_list_from_str_list(row['smile'].split('|'), smiles_dic)] = 1\n",
        "\n",
        "jac_sim_target = 1 - pairwise_distances(targets_jac, metric='jaccard')\n",
        "jac_sim_enzyme = 1 - pairwise_distances(enzymes_jac, metric='jaccard')\n",
        "jac_sim_pathways = 1 - pairwise_distances(pathways_jac, metric='jaccard')\n",
        "jac_sim_smiles = 1 - pairwise_distances(smiles_jac, metric='jaccard')\n",
        "\n",
        "target_PCA = PCA(n_components=len(jac_sim_target))\n",
        "enzyme_PCA = PCA(n_components=len(jac_sim_enzyme))\n",
        "pathway_PCA = PCA(n_components=len(jac_sim_pathways))\n",
        "smile_PCA = PCA(n_components=len(jac_sim_smiles))\n",
        "\n",
        "target_PCA.fit(jac_sim_target)\n",
        "jac_sim_df_target = pd.DataFrame(target_PCA.transform(jac_sim_target))\n",
        "\n",
        "enzyme_PCA.fit(jac_sim_enzyme)\n",
        "jac_sim_df_enzyme = pd.DataFrame(enzyme_PCA.transform(jac_sim_enzyme))\n",
        "\n",
        "pathway_PCA.fit(jac_sim_pathways)\n",
        "jac_sim_df_pathways = pd.DataFrame(pathway_PCA.transform(jac_sim_pathways))\n",
        "\n",
        "smile_PCA.fit(jac_sim_smiles)\n",
        "jac_sim_df_smiles = pd.DataFrame(smile_PCA.transform(jac_sim_smiles))\n",
        "\n",
        "#print(jac_sim_df_target.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulpGiI0-GhD_",
        "outputId": "33263aae-4a94-43a2-9219-ee15c64cd3a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVgk8wg4k7cM"
      },
      "source": [
        "### Extract drug event type interactions from event_db (from Deng et al)\n",
        "\n",
        "These interactions will be used to form our positive examples, negative examples, and a complete list of drug-drug interactions for use in generating our graph embedding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_drug_name = df_raw_drug.set_index('name')\n",
        "\n",
        "df_raw_extraction['event'] = df_raw_extraction['mechanism'] + ' ' + df_raw_extraction['action']\n",
        "\n",
        "df_raw_events = df_raw_extraction['event'].value_counts().to_frame()\n",
        "df_raw_events['event_index'] = np.arange(df_raw_events.shape[0])\n",
        "\n",
        "df_raw_full_pos = df_raw_extraction.join(df_raw_events, on='event')[['drugA', 'drugB', 'event_index']]\n",
        "df_raw_full_pos = df_raw_full_pos.join(df_raw_drug_name['index'], on='drugA')\n",
        "df_raw_full_pos = df_raw_full_pos.join(df_raw_drug_name['index'], on='drugB', rsuffix='_drugB')\n",
        "df_raw_full_pos = df_raw_full_pos[['event_index', 'index', 'index_drugB']]\n",
        "\n",
        "df_raw_events = df_raw_events.reset_index()[['event', 'count']]\n",
        "\n",
        "used_pairs = np.identity(len(df_raw_drug_name.index))\n",
        "# could also sort ints to ensure consistent ordering instead of making matrix symmetrical\n",
        "for index, row in df_raw_full_pos.iterrows():\n",
        "    used_pairs[row['index'], row['index_drugB']] = 1\n",
        "    used_pairs[row['index_drugB'], row['index']] = 1\n",
        "\n",
        "df_raw_all_neg = np.zeros((len(df_raw_full_pos.index), 2))\n",
        "\n",
        "count = 0\n",
        "while count < len(df_raw_all_neg):\n",
        "    # could also sort ints to ensure consistent ordering instead of making matrix symmetrical\n",
        "    rand_pair = np.random.randint(len(df_raw_drug_name.index), size=2)\n",
        "    while used_pairs[rand_pair[0], rand_pair[1]] == 1 or used_pairs[rand_pair[1], rand_pair[0]] == 1:\n",
        "        rand_pair = np.random.randint(len(df_raw_drug_name.index), size=2)\n",
        "\n",
        "    used_pairs[rand_pair[0], rand_pair[1]] = 1\n",
        "    used_pairs[rand_pair[1], rand_pair[0]] = 1\n",
        "    df_raw_all_neg[count] = rand_pair\n",
        "    count += 1\n",
        "\n",
        "df_raw_all_neg = pd.DataFrame(df_raw_all_neg, columns=['drug1', 'drug2'], dtype=np.int64)\n",
        "df_raw_full_pos = df_raw_full_pos.rename(columns={'event_index': 'event_num', 'index': 'drug1', 'index_drugB': 'drug2'})\n",
        "\n",
        "#print(df_raw_full_pos.head())\n",
        "#print(df_raw_all_neg.head())\n",
        "#print(df_raw_events)"
      ],
      "metadata": {
        "id": "RP1GVwtzSYWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_similarity_matrix(name, matrix):\n",
        "    file_path = f'/content/{name}.txt'\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write('572 572\\n')\n",
        "        for index, row in matrix.iterrows():\n",
        "            file.write(f'{index} ')\n",
        "            file.write(\" \".join(str(val) for val in row.tolist()) + '\\n')\n",
        "\n",
        "if not USE_GIVEN_DATA:\n",
        "    save_similarity_matrix('enzyme', jac_sim_df_enzyme)\n",
        "    save_similarity_matrix('target', jac_sim_df_target)\n",
        "    save_similarity_matrix('pathway', jac_sim_df_pathways)\n",
        "    save_similarity_matrix('substructure', jac_sim_df_smiles)"
      ],
      "metadata": {
        "id": "rXZG-uGE-7F-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9zwGkkVi_bE"
      },
      "source": [
        "##### Process similarity matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xG7uiYdlMQd",
        "outputId": "9780778e-1ff5-4cdb-f722-1f95021d23cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on enzyme.txt: dimensions 572x572\n",
            "Working on pathway.txt: dimensions 572x572\n",
            "Working on substructure.txt: dimensions 572x572\n",
            "Working on target.txt: dimensions 572x572\n",
            "Enzyme Matrix first 5 lines:\n",
            "        0         1         2         3         4         5         6    \\\n",
            "0  4.593168 -0.541539 -0.419176 -0.585470  0.635045 -0.553429 -0.638244   \n",
            "1 -1.746907 -0.047556  0.115552  0.256290  0.833815  0.055187 -0.252872   \n",
            "2 -1.604115  0.854200  0.054576  0.923948 -0.645173 -0.069596 -0.404109   \n",
            "3 -1.769781 -0.921454 -0.756435 -0.686417  0.678216 -0.013575  0.142495   \n",
            "4  3.707746  2.830004 -0.844595  0.383860 -0.122485 -0.528834  0.652127   \n",
            "\n",
            "        7         8         9    ...           562           563  \\\n",
            "0  0.058711  0.458386  0.214047  ...  0.000000e+00 -4.857226e-17   \n",
            "1  0.095018 -0.013088  0.119412  ...  3.209238e-17 -1.561251e-17   \n",
            "2 -0.331794  0.545126  0.175939  ... -1.561251e-17  1.734723e-18   \n",
            "3 -0.032153 -0.427615 -0.124185  ...  6.938894e-18  1.023487e-16   \n",
            "4  0.061080 -0.276268 -0.005134  ... -1.353084e-16 -1.387779e-16   \n",
            "\n",
            "            564           565           566           567           568  \\\n",
            "0  3.122502e-17  7.979728e-17 -1.387779e-17 -9.714451e-17  1.110223e-16   \n",
            "1  1.387779e-17 -5.204170e-18  1.214306e-17  2.775558e-17 -1.734723e-18   \n",
            "2 -2.602085e-18 -2.775558e-17 -3.469447e-17 -7.806256e-18  2.775558e-17   \n",
            "3 -4.466913e-17 -3.165870e-17  2.081668e-17  5.984796e-17  5.204170e-17   \n",
            "4  1.179612e-16  2.636780e-16 -1.387779e-17 -7.285839e-17 -1.630640e-16   \n",
            "\n",
            "            569           570           571  \n",
            "0 -1.387779e-16  2.046974e-16 -9.020562e-17  \n",
            "1  6.591949e-17 -5.117434e-17 -7.216450e-16  \n",
            "2  7.632783e-17 -7.502679e-17 -7.103693e-16  \n",
            "3 -2.428613e-17 -4.770490e-17  2.081668e-16  \n",
            "4 -1.110223e-16  1.006140e-16 -3.053113e-16  \n",
            "\n",
            "[5 rows x 572 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_similarity_matrix(file_path):\n",
        "    file_name = file_path.split('/')[-1]  #Get just file name from path\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        #take the first line as the dimensions\n",
        "        dimensions = lines[0].strip().split()\n",
        "        rows, cols = int(dimensions[0]), int(dimensions[1])\n",
        "        print(f'Working on {file_name}: dimensions {rows}x{cols}')\n",
        "\n",
        "        #the rest of the lines contain the matrix\n",
        "        data = []\n",
        "        for i, line in enumerate(lines[1:]):\n",
        "            row_data = line.strip().split()[1:]  # Skip the row number\n",
        "\n",
        "            #convert to float and handle scientific notation\n",
        "            try:\n",
        "                row_data = [float(x) for x in row_data]\n",
        "            except ValueError as e:\n",
        "                print(f\"Error in line {i+2}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if len(row_data) != cols:\n",
        "                raise ValueError(f\"Row {i+2} does not contain {cols} values. Row data: {row_data}\")\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        matrix = pd.DataFrame(data)\n",
        "        if matrix.shape != (rows, cols):\n",
        "            raise ValueError(f\"Data does not match specified dimensions {rows}x{cols}\")\n",
        "        return matrix\n",
        "\n",
        "enzyme_matrix = load_similarity_matrix('/content/enzyme.txt')\n",
        "pathway_matrix = load_similarity_matrix('/content/pathway.txt')\n",
        "substructure_matrix = load_similarity_matrix('/content/substructure.txt')\n",
        "target_matrix = load_similarity_matrix('/content/target.txt')\n",
        "\n",
        "\n",
        "print('Enzyme Matrix first 5 lines:')\n",
        "print(enzyme_matrix.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9QLK7c1p7VV"
      },
      "source": [
        "## Process training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bKCVMK8em9NF"
      },
      "outputs": [],
      "source": [
        "# Define a function to load the data into a DataFrame and label the columns\n",
        "def load_data(file_path, has_interaction=True, has_event_num=True):\n",
        "    #testing data, which can have 0 or 1 interactions\n",
        "    if has_event_num and has_interaction:\n",
        "        column_names = ['event_num', 'drug1', 'drug2', 'interaction']\n",
        "    #training data which does not include interaction because it's always 1\n",
        "    elif has_event_num:\n",
        "        column_names = ['event_num', 'drug1', 'drug2']\n",
        "    #All neg which only contains drug1, drug 2 and no interactions or events\n",
        "    else:\n",
        "        column_names = ['drug1', 'drug2']\n",
        "\n",
        "    data = pd.read_csv(file_path, sep=' ', header=None, names=column_names)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Paths to the files in the Colab environment\n",
        "test_file_path = '/content/test.txt'\n",
        "train_file_path = '/content/train.txt'\n",
        "valid_file_path = '/content/valid.txt'\n",
        "all_neg_file_path = '/content/all_neg2.txt'\n",
        "full_pos_file_path = '/content/full_pos2.txt'\n",
        "\n",
        "# Load the data into DataFrames\n",
        "test_df = load_data(test_file_path, has_interaction=True)\n",
        "train_df = load_data(train_file_path, has_interaction=False)\n",
        "valid_df = load_data(valid_file_path, has_interaction=True)\n",
        "all_neg_df = load_data(all_neg_file_path, has_interaction=False, has_event_num=False)\n",
        "full_pos_df = load_data(full_pos_file_path, has_interaction=False)\n",
        "\n",
        "# print(\"Test DataFrame:\")\n",
        "# print(test_df.head())\n",
        "# print('\\n')\n",
        "# print(\"Train DataFrame:\")\n",
        "# print(train_df.head())\n",
        "# print('\\n')\n",
        "# print(f'train drug1 range: {train_df.drug1.min()}-{train_df.drug1.max()}')\n",
        "# print(f'train drug2 range: {train_df.drug2.min()}-{train_df.drug2.max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTq-dBaKk7cN"
      },
      "source": [
        "\n",
        "#### Data Analysis\n",
        "\n",
        "From our four raw features, we have the below unique values:\n",
        "* 202 unique enzymes\n",
        "* 1162 unique drug targets\n",
        "* 583 unique smile paths\n",
        "* 957 unqiue pathways\n",
        "\n",
        "The distribution of target, smile, and pathways encodings are largely even. The distribution for enzymnes are skewed towards the most commonly impacted enzymes.\n",
        "\n",
        "Following processing, all similarity matrices have a shape of 572x572. This is a result of the jaccard similarity, which we use to represent relationships between drug features. These matrices will be the node attributes within our GNNs to generate embeddings for prediction by our final models.\n",
        "\n",
        "#### Interaction Analyis\n",
        "\n",
        "As shown below, we have an even distribution of \"positive\" (interaction) and \"negative\" (no-interaction) events for 37264 each, with a total for 65 unique interaction types. However, we have a massive skew in interaction type (shown by index and head) with 3 interaction types accounting for 66% of the interactions. This massive skew will make it difficult for the model to train to less prevalent interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Num target features: {len(targets)}')\n",
        "print(f'Num enzyme features: {len(enzymes)}')\n",
        "print(f'Num pathway features: {len(pathways)}')\n",
        "print(f'Num substructure features: {len(smiles)}')\n",
        "\n",
        "print(\"\\nInteraction Types:\")\n",
        "print(df_raw_events.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLg7hA6IXl9e",
        "outputId": "ae93f03f-b3c6-4326-8005-1a1ddc9ebaa9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num target features: 1162\n",
            "Num enzyme features: 202\n",
            "Num pathway features: 957\n",
            "Num substructure features: 583\n",
            "\n",
            "Interaction Types:\n",
            "                                              event  count\n",
            "0                           The metabolism decrease   9810\n",
            "1  The risk or severity of adverse effects increase   9496\n",
            "2                  The serum concentration increase   5646\n",
            "3                  The serum concentration decrease   2386\n",
            "4                 The therapeutic efficacy decrease   1312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XY--83pk7cP"
      },
      "source": [
        "### Generate Train/Test/Validate Splits\n",
        "\n",
        "We will now create our train, test, and validate splits from the drug-drug interaction dataframes we generated from the event_db.\n",
        "\n",
        "We will use a standard (70-20-10, train, test, validation) split, giving us:\n",
        "* 52169 training samples\n",
        "* 14906 training samples\n",
        "* 7453 validation samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpFAh1Eg0ELF",
        "outputId": "92ba68fb-c001-4840-c4c7-8e2e2a06e71a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size: 52169\n",
            "Validation data size: 7453\n",
            "Test data size: 14906\n"
          ]
        }
      ],
      "source": [
        "if not USE_GIVEN_DATA:\n",
        "    full_pos_df = df_raw_full_pos\n",
        "    all_neg_df = df_raw_all_neg\n",
        "\n",
        "#select equal number of negative examples from all_neg_df\n",
        "num_negatives = len(full_pos_df)\n",
        "all_neg_sample = all_neg_df.sample(n=num_negatives, random_state=42)\n",
        "\n",
        "# Add an 'event_num' column with a placeholder value\n",
        "all_neg_sample['event_num'] = -1\n",
        "\n",
        "#Combine positive and negative examples for neural network training\n",
        "nn_data = pd.concat([full_pos_df, all_neg_sample]).reset_index(drop=True)\n",
        "\n",
        "#split data into train, validation, and test sets (70-10-20 split)\n",
        "train_df, test_df = train_test_split(nn_data, test_size=0.3, random_state=2)\n",
        "valid_df, test_df = train_test_split(test_df, test_size=(2/3), random_state=2)  #split last 30% into 10% and 20% valid/test\n",
        "\n",
        "test_df['interaction'] = test_df['event_num'].apply(lambda x: 1 if 0 <= x <= 64 else 0)\n",
        "\n",
        "# Verify the splits\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Validation data size: {len(valid_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzxpL8_Ok7cN"
      },
      "source": [
        "### GNN Training for Embedding Extraction\n",
        "\n",
        "We will create graph embeddings. These will serve as the drug feature vectors for use in our feed forward neural network. The existing PyTorch implementation of the $GATNE^{6}$ embedding method found [here](https://github.com/THUDM/GATNE) was implemented below.\n",
        "\n",
        "To perform this, we will make a graph of nodes (drugs) and edges (events - event num). Four graphs in total are made (one for each of the property types we want to make embeddings for - enzyme, pathway, substructure, and target). The features of the nodes in the graph will be a row of the feature matrix, corresponding to that drug's similarity to each of the other drugs in the network on that property type (enzyme for instance). A random walk of the graph with a context window is done for each drug and edge type to create one embedding per drug per interaction type.\n",
        "\n",
        "The output dimension of these graph embeddings is 572x32x66 which corresponds to the number of drugs x the embedding dimension x the number of events. The embedding dimension is a tuned hyperparameter from the original work, but can theoretically be changed. Finally, the last two dimensions of these matrices will be concatenated to form raw feature vectors for the nerual network (of dimension 572x2080 where 2080=32x65). \"Raw\" because we will still need to perform some further operations before they are ready to go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HriU-Txu7Pmu",
        "outputId": "76fc4471-347c-404e-fc4d-888ea40ab1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 32  #Default 32\n",
        "event_num = 65  #Default 65 DO NOT CHANGE\n",
        "\n",
        "#Dictionary of feature matrices to use\n",
        "#Not currently used\n",
        "\n",
        "feature_matrices = {}\n",
        "if USE_GIVEN_DATA:\n",
        "    feature_matrices['enzyme'] = enzyme_matrix\n",
        "    feature_matrices['pathway'] = pathway_matrix\n",
        "    feature_matrices['substructure'] =  substructure_matrix\n",
        "    feature_matrices['target'] = target_matrix\n",
        "else:\n",
        "    feature_matrices['enzyme'] = jac_sim_df_enzyme\n",
        "    feature_matrices['pathway'] = jac_sim_df_pathways\n",
        "    feature_matrices['substructure'] =  jac_sim_df_smiles\n",
        "    feature_matrices['target'] = jac_sim_df_target\n",
        "\n",
        "\n",
        "#Use GPU if available. This will be much faster for training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yy2mPqNVt6PV"
      },
      "outputs": [],
      "source": [
        "walk_length = 10 #Default 10\n",
        "walks_per_node = 20 #Default 20\n",
        "window_size = 5 #Default 5\n",
        "negative_samples = 5 #Default 5\n",
        "learning_rate = 0.01 #Default 0.01\n",
        "epochs = 1 #Default 1\n",
        "batch_size=64 #Default 64, lower this if RAM spikes are crashing Colab\n",
        "num_workers=16 #Default 16\n",
        "patience_num = 5 #no default (because we default to 1 epoch)\n",
        "save_path = '/content'\n",
        "edge_dim = 10 #Degault 10\n",
        "att_dim = 20 #Default 20\n",
        "negative_samples = 5 #Default 5\n",
        "neighbor_samples = 20 #Default 10\n",
        "eval_type = 'all'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OROuvXBak7cO"
      },
      "source": [
        "##### Define graph edges\n",
        "There are two choices for how to define the graph neural network:\n",
        "* We can either include negative samples (drug-drug pairs that DO NOT interact with eachother)\n",
        "* Omit negative examples.\n",
        "\n",
        "The original paper does *not* use negative examples in training, and only includes negative samples in the validation and test sets. We will improve upon this by introducing a 50/50 split of positive and negative examples in our training data. It may be useful to use different splits of positive and negative examples for different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GOGKiQEOkNoH"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, count, index):\n",
        "        self.count = count\n",
        "        self.index = index\n",
        "\n",
        "#Batches for training the GNN\n",
        "def get_batches(pairs, neighbors, batch_size):\n",
        "    n_batches = (len(pairs) + (batch_size - 1)) // batch_size\n",
        "\n",
        "    for idx in range(n_batches):\n",
        "        x, y, t, neigh = [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "            index = idx * batch_size + i\n",
        "            if index >= len(pairs):\n",
        "                break\n",
        "            x.append(pairs[index][0])\n",
        "            y.append(pairs[index][1])\n",
        "            t.append(pairs[index][2])\n",
        "            neigh.append(neighbors[pairs[index][0]])\n",
        "        yield torch.tensor(x), torch.tensor(y), torch.tensor(t), torch.tensor(neigh)\n",
        "\n",
        "def get_G_from_edges(edges):\n",
        "    edge_dict = defaultdict(set)\n",
        "    for edge in edges:\n",
        "        u, v = str(edge[0]), str(edge[1])\n",
        "        edge_dict[u].add(v)\n",
        "        edge_dict[v].add(u)\n",
        "    return edge_dict\n",
        "\n",
        "def load_training_data(f_name):\n",
        "    print('Loading data from:', f_name)\n",
        "    edge_data_by_type = dict()\n",
        "    all_nodes = list()\n",
        "    with open(f_name, 'r') as f:\n",
        "        for line in f:\n",
        "            words = line[:-1].split(' ')\n",
        "            if words[0] not in edge_data_by_type:\n",
        "                edge_data_by_type[words[0]] = list()\n",
        "            x, y = words[1], words[2]\n",
        "            edge_data_by_type[words[0]].append((x, y))\n",
        "            all_nodes.append(x)\n",
        "            all_nodes.append(y)\n",
        "    all_nodes = list(set(all_nodes))\n",
        "    print('Total training nodes: ' + str(len(all_nodes)))\n",
        "    return edge_data_by_type\n",
        "\n",
        "\n",
        "def load_testing_data(f_name):\n",
        "    print('Loading data from:', f_name)\n",
        "    true_edge_data_by_type = dict()\n",
        "    false_edge_data_by_type = dict()\n",
        "    all_nodes = list()\n",
        "    with open(f_name, 'r') as f:\n",
        "        for line in f:\n",
        "            words = line[:-1].split(' ')\n",
        "            x, y = words[1], words[2]\n",
        "            if int(words[3]) == 1:\n",
        "                if words[0] not in true_edge_data_by_type:\n",
        "                    true_edge_data_by_type[words[0]] = list()\n",
        "                true_edge_data_by_type[words[0]].append((x, y))\n",
        "            else:\n",
        "                if words[0] not in false_edge_data_by_type:\n",
        "                    false_edge_data_by_type[words[0]] = list()\n",
        "                false_edge_data_by_type[words[0]].append((x, y))\n",
        "            all_nodes.append(x)\n",
        "            all_nodes.append(y)\n",
        "    all_nodes = list(set(all_nodes))\n",
        "    return true_edge_data_by_type, false_edge_data_by_type\n",
        "\n",
        "def load_node_type(f_name):\n",
        "    print('Loading node type from:', f_name)\n",
        "    node_type = {}\n",
        "    with open(f_name, 'r') as f:\n",
        "        for line in f:\n",
        "            items = line.strip().split()\n",
        "            node_type[items[0]] = items[1]\n",
        "    return node_type\n",
        "\n",
        "def load_feature_data(f_name):\n",
        "    feature_dic = {}\n",
        "    with open(f_name, 'r') as f:\n",
        "        first = True\n",
        "        for line in f:\n",
        "            if first:\n",
        "                first = False\n",
        "                continue\n",
        "            items = line.strip().split()\n",
        "            feature_dic[items[0]] = items[1:]\n",
        "    return feature_dic\n",
        "\n",
        "def generate_walks(network_data, num_walks, walk_length, schema, file_name, num_workers):\n",
        "    if schema is not None:\n",
        "        node_type = load_node_type(file_name + '/node_type.txt')\n",
        "    else:\n",
        "        node_type = None\n",
        "\n",
        "    all_walks = []\n",
        "    for layer_id, layer_name in enumerate(network_data):\n",
        "        tmp_data = network_data[layer_name]\n",
        "        # start to do the random walk on a layer\n",
        "\n",
        "        layer_walker = RWGraph(get_G_from_edges(tmp_data), node_type, num_workers)\n",
        "        print('Generating random walks for event_num', layer_id)\n",
        "        layer_walks = layer_walker.simulate_walks(num_walks, walk_length, schema=schema)\n",
        "\n",
        "        all_walks.append(layer_walks)\n",
        "\n",
        "    print('Finish generating the walks')\n",
        "\n",
        "    return all_walks\n",
        "\n",
        "def generate_pairs(all_walks, vocab, window_size, num_workers):\n",
        "    pairs = []\n",
        "    skip_window = window_size // 2\n",
        "    for layer_id, walks in enumerate(all_walks):\n",
        "        print('Generating training pairs for event_num', layer_id)\n",
        "        for walk in tqdm(walks):\n",
        "            for i in range(len(walk)):\n",
        "                for j in range(1, skip_window + 1):\n",
        "                    if i - j >= 0:\n",
        "                        pairs.append((vocab[walk[i]].index, vocab[walk[i - j]].index, layer_id))\n",
        "                    if i + j < len(walk):\n",
        "                        pairs.append((vocab[walk[i]].index, vocab[walk[i + j]].index, layer_id))\n",
        "    return pairs\n",
        "\n",
        "def generate_vocab(all_walks):\n",
        "    index2word = []\n",
        "    raw_vocab = defaultdict(int)\n",
        "\n",
        "    for layer_id, walks in enumerate(all_walks):\n",
        "        print('Counting vocab for event_num', layer_id)\n",
        "        for walk in tqdm(walks):\n",
        "            for word in walk:\n",
        "                raw_vocab[word] += 1\n",
        "\n",
        "    vocab = {}\n",
        "    for word, v in iteritems(raw_vocab):\n",
        "        vocab[word] = Vocab(count=v, index=len(index2word))\n",
        "        index2word.append(word)\n",
        "\n",
        "    index2word.sort(key=lambda word: vocab[word].count, reverse=True)\n",
        "    for i, word in enumerate(index2word):\n",
        "        vocab[word].index = i\n",
        "\n",
        "    return vocab, index2word\n",
        "\n",
        "def load_walks(walk_file):\n",
        "    print('Loading walks')\n",
        "    all_walks = []\n",
        "    with open(walk_file, 'r') as f:\n",
        "        for line in f:\n",
        "            content = line.strip().split()\n",
        "            layer_id = int(content[0])\n",
        "            if layer_id >= len(all_walks):\n",
        "                all_walks.append([])\n",
        "            all_walks[layer_id].append(content[1:])\n",
        "    return all_walks\n",
        "\n",
        "def save_walks(walk_file, all_walks):\n",
        "    with open(walk_file, 'w') as f:\n",
        "        for layer_id, walks in enumerate(all_walks):\n",
        "            print('Saving walks for event_num', layer_id)\n",
        "            for walk in tqdm(walks):\n",
        "                f.write(' '.join([str(layer_id)] + [str(x) for x in walk]) + '\\n')\n",
        "\n",
        "def generate(network_data, num_walks, walk_length, schema, file_name, window_size, num_workers, walk_file):\n",
        "    if walk_file is not None:\n",
        "        all_walks = load_walks(walk_file)\n",
        "    else:\n",
        "        all_walks = generate_walks(network_data, num_walks, walk_length, schema, file_name, num_workers)\n",
        "        save_walks(file_name + '/walks.txt', all_walks)\n",
        "    vocab, index2word = generate_vocab(all_walks)\n",
        "    train_pairs = generate_pairs(all_walks, vocab, window_size, num_workers)\n",
        "\n",
        "    return vocab, index2word, train_pairs\n",
        "\n",
        "def generate_neighbors(network_data, vocab, num_nodes, edge_types, neighbor_samples):\n",
        "    edge_type_count = len(edge_types)\n",
        "    neighbors = [[[] for __ in range(edge_type_count)] for _ in range(num_nodes)]\n",
        "    for r in range(edge_type_count):\n",
        "        print('Generating neighbors for event_num', r)\n",
        "        g = network_data[edge_types[r]]\n",
        "        for (x, y) in tqdm(g):\n",
        "            ix = vocab[x].index\n",
        "            iy = vocab[y].index\n",
        "            neighbors[ix][r].append(iy)\n",
        "            neighbors[iy][r].append(ix)\n",
        "        for i in range(num_nodes):\n",
        "            if len(neighbors[i][r]) == 0:\n",
        "                neighbors[i][r] = [i] * neighbor_samples\n",
        "            elif len(neighbors[i][r]) < neighbor_samples:\n",
        "                neighbors[i][r].extend(list(np.random.choice(neighbors[i][r], size=neighbor_samples-len(neighbors[i][r]))))\n",
        "            elif len(neighbors[i][r]) > neighbor_samples:\n",
        "                neighbors[i][r] = list(np.random.choice(neighbors[i][r], size=neighbor_samples))\n",
        "    return neighbors\n",
        "\n",
        "def get_score(local_model, node1, node2):\n",
        "    try:\n",
        "        vector1 = local_model[node1]\n",
        "        vector2 = local_model[node2]\n",
        "        return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "\n",
        "def evaluate(model, true_edges, false_edges):\n",
        "    true_list = list()\n",
        "    prediction_list = list()\n",
        "    true_num = 0\n",
        "    for edge in true_edges:\n",
        "        tmp_score = get_score(model, str(edge[0]), str(edge[1]))\n",
        "        if tmp_score is not None:\n",
        "            true_list.append(1)\n",
        "            prediction_list.append(tmp_score)\n",
        "            true_num += 1\n",
        "\n",
        "    for edge in false_edges:\n",
        "        tmp_score = get_score(model, str(edge[0]), str(edge[1]))\n",
        "        if tmp_score is not None:\n",
        "            true_list.append(0)\n",
        "            prediction_list.append(tmp_score)\n",
        "\n",
        "    sorted_pred = prediction_list[:]\n",
        "    sorted_pred.sort()\n",
        "    threshold = sorted_pred[-true_num]\n",
        "\n",
        "    y_pred = np.zeros(len(prediction_list), dtype=np.int32)\n",
        "    for i in range(len(prediction_list)):\n",
        "        if prediction_list[i] >= threshold:\n",
        "            y_pred[i] = 1\n",
        "\n",
        "    y_true = np.array(true_list)\n",
        "    y_scores = np.array(prediction_list)\n",
        "    ps, rs, _ = precision_recall_curve(y_true, y_scores)\n",
        "    return roc_auc_score(y_true, y_scores), f1_score(y_true, y_pred), auc(rs, ps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "M3XSwvb5gwAU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import multiprocessing\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def walk(args):\n",
        "    walk_length, start, schema = args\n",
        "    # Simulate a random walk starting from start node.\n",
        "    rand = random.Random()\n",
        "\n",
        "    if schema:\n",
        "        schema_items = schema.split('-')\n",
        "        assert schema_items[0] == schema_items[-1]\n",
        "\n",
        "    walk = [start]\n",
        "    while len(walk) < walk_length:\n",
        "        cur = walk[-1]\n",
        "        candidates = []\n",
        "        for node in G[cur]:\n",
        "            if schema == '' or node_type[node] == schema_items[len(walk) % (len(schema_items) - 1)]:\n",
        "                candidates.append(node)\n",
        "        if candidates:\n",
        "            walk.append(rand.choice(candidates))\n",
        "        else:\n",
        "            break\n",
        "    return [str(node) for node in walk]\n",
        "\n",
        "def initializer(init_G, init_node_type):\n",
        "    global G\n",
        "    G = init_G\n",
        "    global node_type\n",
        "    node_type = init_node_type\n",
        "\n",
        "class RWGraph():\n",
        "    def __init__(self, nx_G, node_type_arr=None, num_workers=16):\n",
        "        self.G = nx_G\n",
        "        self.node_type = node_type_arr\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def node_list(self, nodes, num_walks):\n",
        "        for loop in range(num_walks):\n",
        "            for node in nodes:\n",
        "                yield node\n",
        "\n",
        "    def simulate_walks(self, num_walks, walk_length, schema=None):\n",
        "        all_walks = []\n",
        "        nodes = list(self.G.keys())\n",
        "        random.shuffle(nodes)\n",
        "\n",
        "        if schema is None:\n",
        "            with multiprocessing.Pool(self.num_workers, initializer=initializer, initargs=(self.G, self.node_type)) as pool:\n",
        "                all_walks = list(pool.imap(walk, ((walk_length, node, '') for node in tqdm(self.node_list(nodes, num_walks))), chunksize=256))\n",
        "        else:\n",
        "            schema_list = schema.split(',')\n",
        "            for schema_iter in schema_list:\n",
        "                with multiprocessing.Pool(self.num_workers, initializer=initializer, initargs=(self.G, self.node_type)) as pool:\n",
        "                    walks = list(pool.imap(walk, ((walk_length, node, schema_iter) for node in tqdm(self.node_list(nodes, num_walks)) if schema_iter.split('-')[0] == self.node_type[node]), chunksize=512))\n",
        "                all_walks.extend(walks)\n",
        "\n",
        "        return all_walks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S2oZQMWj9MG0"
      },
      "outputs": [],
      "source": [
        "class GATNEModel(nn.Module):\n",
        "    def __init__(\n",
        "        self, num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
        "    ):\n",
        "        super(GATNEModel, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding_u_size = embedding_u_size\n",
        "        self.edge_type_count = edge_type_count\n",
        "        self.dim_a = dim_a\n",
        "\n",
        "        self.features = None\n",
        "        if features is not None:\n",
        "            self.features = features\n",
        "            feature_dim = self.features.shape[-1]\n",
        "            self.embed_trans = Parameter(torch.FloatTensor(feature_dim, embedding_size))\n",
        "            self.u_embed_trans = Parameter(torch.FloatTensor(edge_type_count, feature_dim, embedding_u_size))\n",
        "        else:\n",
        "            self.node_embeddings = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
        "            self.node_type_embeddings = Parameter(\n",
        "                torch.FloatTensor(num_nodes, edge_type_count, embedding_u_size)\n",
        "            )\n",
        "        self.trans_weights = Parameter(\n",
        "            torch.FloatTensor(edge_type_count, embedding_u_size, embedding_size)\n",
        "        )\n",
        "        self.trans_weights_s1 = Parameter(\n",
        "            torch.FloatTensor(edge_type_count, embedding_u_size, dim_a)\n",
        "        )\n",
        "        self.trans_weights_s2 = Parameter(torch.FloatTensor(edge_type_count, dim_a, 1))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.features is not None:\n",
        "            self.embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "            self.u_embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "        else:\n",
        "            self.node_embeddings.data.uniform_(-1.0, 1.0)\n",
        "            self.node_type_embeddings.data.uniform_(-1.0, 1.0)\n",
        "        self.trans_weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "        self.trans_weights_s1.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "        self.trans_weights_s2.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "\n",
        "    def forward(self, train_inputs, train_types, node_neigh):\n",
        "        if self.features is None:\n",
        "            node_embed = self.node_embeddings[train_inputs]\n",
        "            node_embed_neighbors = self.node_type_embeddings[node_neigh]\n",
        "        else:\n",
        "            node_embed = torch.mm(self.features[train_inputs], self.embed_trans)\n",
        "            node_embed_neighbors = torch.einsum('bijk,akm->bijam', self.features[node_neigh], self.u_embed_trans)\n",
        "        node_embed_tmp = torch.diagonal(node_embed_neighbors, dim1=1, dim2=3).permute(0, 3, 1, 2)\n",
        "        node_type_embed = torch.sum(node_embed_tmp, dim=2)\n",
        "\n",
        "        trans_w = self.trans_weights[train_types]\n",
        "        trans_w_s1 = self.trans_weights_s1[train_types]\n",
        "        trans_w_s2 = self.trans_weights_s2[train_types]\n",
        "\n",
        "        attention = F.softmax(\n",
        "            torch.matmul(\n",
        "                torch.tanh(torch.matmul(node_type_embed, trans_w_s1)), trans_w_s2\n",
        "            ).squeeze(2),\n",
        "            dim=1,\n",
        "        ).unsqueeze(1)\n",
        "        node_type_embed = torch.matmul(attention, node_type_embed)\n",
        "        node_embed = node_embed + torch.matmul(node_type_embed, trans_w).squeeze(1)\n",
        "\n",
        "        last_node_embed = F.normalize(node_embed, dim=1)\n",
        "\n",
        "        return last_node_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k-uhJyhlkpbT"
      },
      "outputs": [],
      "source": [
        "class NSLoss(nn.Module):\n",
        "    def __init__(self, num_nodes, num_sampled, embedding_size):\n",
        "        super(NSLoss, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_sampled = num_sampled\n",
        "        self.embedding_size = embedding_size\n",
        "        self.weights = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
        "        self.sample_weights = F.normalize(\n",
        "            torch.Tensor(\n",
        "                [\n",
        "                    (math.log(k + 2) - math.log(k + 1)) / math.log(num_nodes + 1)\n",
        "                    for k in range(num_nodes)\n",
        "                ]\n",
        "            ),\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "\n",
        "    def forward(self, input, embs, label):\n",
        "        n = input.shape[0]\n",
        "        log_target = torch.log(\n",
        "            torch.sigmoid(torch.sum(torch.mul(embs, self.weights[label]), 1))\n",
        "        )\n",
        "        negs = torch.multinomial(\n",
        "            self.sample_weights, self.num_sampled * n, replacement=True\n",
        "        ).view(n, self.num_sampled)\n",
        "        noise = torch.neg(self.weights[negs])\n",
        "        sum_log_sampled = torch.sum(\n",
        "            torch.log(torch.sigmoid(torch.bmm(noise, embs.unsqueeze(2)))), 1\n",
        "        ).squeeze()\n",
        "\n",
        "        loss = log_target + sum_log_sampled\n",
        "        return -loss.sum() / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zZMjHF4__Xle"
      },
      "outputs": [],
      "source": [
        "def train_model(network_data, feature_dic, feature_name):\n",
        "    vocab, index2word, train_pairs = generate(network_data, walks_per_node, walk_length, schema=None, file_name=save_path, window_size=window_size, num_workers=num_workers, walk_file=None)\n",
        "\n",
        "    edge_types = list(network_data.keys())\n",
        "\n",
        "    num_nodes = len(index2word)\n",
        "    edge_type_count = len(edge_types)\n",
        "    #epochs = epochs\n",
        "    #batch_size = args.batch_size\n",
        "    embedding_size = embedding_dim\n",
        "    embedding_u_size = edge_dim\n",
        "    u_num = edge_type_count\n",
        "    num_sampled = negative_samples\n",
        "    dim_a = att_dim\n",
        "    att_head = 1\n",
        "    #neighbor_samples = neighbor_samples\n",
        "    print(u_num)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    neighbors = generate_neighbors(network_data, vocab, num_nodes, edge_types, neighbor_samples)\n",
        "\n",
        "    features = None\n",
        "    if feature_dic is not None:\n",
        "        feature_dim = len(list(feature_dic.values())[0])\n",
        "        print('feature dimension: ' + str(feature_dim))\n",
        "        features = np.zeros((num_nodes, feature_dim), dtype=np.float32)\n",
        "        for key, value in feature_dic.items():\n",
        "            if key in vocab:\n",
        "                features[vocab[key].index, :] = np.array(value)\n",
        "        features = torch.FloatTensor(features).to(device)\n",
        "\n",
        "    model = GATNEModel(\n",
        "        num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
        "    )\n",
        "    nsloss = NSLoss(num_nodes, num_sampled, embedding_size)\n",
        "\n",
        "    model.to(device)\n",
        "    nsloss.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        [{\"params\": model.parameters()}, {\"params\": nsloss.parameters()}], lr=1e-4\n",
        "    )\n",
        "\n",
        "    print(f'Beginning training for {feature_name} model')\n",
        "\n",
        "    best_score = 0\n",
        "    test_score = (0.0, 0.0, 0.0)\n",
        "    patience = 0\n",
        "    for epoch in range(epochs):\n",
        "        random.shuffle(train_pairs)\n",
        "        batches = get_batches(train_pairs, neighbors, batch_size)\n",
        "\n",
        "        data_iter = tqdm(\n",
        "            batches,\n",
        "            desc=\"epoch %d\" % (epoch),\n",
        "            total=(len(train_pairs) + (batch_size - 1)) // batch_size,\n",
        "            bar_format=\"{l_bar}{r_bar}\",\n",
        "        )\n",
        "        avg_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(data_iter):\n",
        "            optimizer.zero_grad()\n",
        "            embs = model(data[0].to(device), data[2].to(device), data[3].to(device),)\n",
        "            loss = nsloss(data[0].to(device), embs, data[1].to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            if i % 5000 == 0:\n",
        "                post_fix = {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"iter\": i,\n",
        "                    \"avg_loss\": avg_loss / (i + 1),\n",
        "                    \"loss\": loss.item(),\n",
        "                }\n",
        "                data_iter.write(str(post_fix))\n",
        "\n",
        "        final_model = dict(zip(edge_types, [dict() for _ in range(edge_type_count)]))\n",
        "\n",
        "        #initialize embeddings of all zeros\n",
        "        final_embeddings = np.zeros((num_nodes, embedding_dim * u_num))\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            train_inputs = torch.tensor([i for _ in range(edge_type_count)]).to(device)\n",
        "            train_types = torch.tensor(list(range(edge_type_count))).to(device)\n",
        "            node_neigh = torch.tensor(\n",
        "                [neighbors[i] for _ in range(edge_type_count)]\n",
        "            ).to(device)\n",
        "            node_emb = model(train_inputs, train_types, node_neigh)\n",
        "            for j in range(edge_type_count):\n",
        "                final_model[edge_types[j]][index2word[i]] = (\n",
        "                    node_emb[j].cpu().detach().numpy()\n",
        "                )\n",
        "\n",
        "                #concatenate and save embeddings\n",
        "                #where i loop is over the drugs (572)\n",
        "                #and j loop is over the event_num (65)\n",
        "                #concatenated_embeddings = torch.cat([node_emb[j].cpu().detach() for j in range(u_num)], dim=1)\n",
        "                #final_embeddings[i, :] = concatenated_embeddings\n",
        "\n",
        "        valid_aucs, valid_f1s, valid_prs = [], [], []\n",
        "        test_aucs, test_f1s, test_prs = [], [], []\n",
        "        for i in range(edge_type_count):\n",
        "            if eval_type == \"all\":\n",
        "                tmp_auc, tmp_f1, tmp_pr = evaluate(\n",
        "                    final_model[edge_types[i]],\n",
        "                    valid_true_data_by_edge[edge_types[i]],\n",
        "                    valid_false_data_by_edge[edge_types[i]],\n",
        "                )\n",
        "                valid_aucs.append(tmp_auc)\n",
        "                valid_f1s.append(tmp_f1)\n",
        "                valid_prs.append(tmp_pr)\n",
        "\n",
        "                tmp_auc, tmp_f1, tmp_pr = evaluate(\n",
        "                    final_model[edge_types[i]],\n",
        "                    testing_true_data_by_edge[edge_types[i]],\n",
        "                    testing_false_data_by_edge[edge_types[i]],\n",
        "                )\n",
        "                test_aucs.append(tmp_auc)\n",
        "                test_f1s.append(tmp_f1)\n",
        "                test_prs.append(tmp_pr)\n",
        "        print(\"valid auc:\", np.mean(valid_aucs))\n",
        "        print(\"valid pr:\", np.mean(valid_prs))\n",
        "        print(\"valid f1:\", np.mean(valid_f1s))\n",
        "\n",
        "        average_auc = np.mean(test_aucs)\n",
        "        average_f1 = np.mean(test_f1s)\n",
        "        average_pr = np.mean(test_prs)\n",
        "\n",
        "        cur_score = np.mean(valid_aucs)\n",
        "        if cur_score > best_score:\n",
        "            best_score = cur_score\n",
        "            test_score = (average_auc, average_f1, average_pr)\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience > patience_num:\n",
        "                print(\"Early Stopping\")\n",
        "                break\n",
        "    return test_score, final_model #final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "29UlzqPoUPFm"
      },
      "outputs": [],
      "source": [
        "file_name = '/content'\n",
        "\n",
        "graph_test_scores = {}\n",
        "graph_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c8l4YvKI0qHg"
      },
      "outputs": [],
      "source": [
        "if TRAIN_GNN:\n",
        "    for name, matrix in feature_matrices.items():\n",
        "        #check if we've already processed this matrix (useful for colab limits)\n",
        "        if graph_models.get(name) is None:\n",
        "            matrix_filepath = save_path + f'/{name}.txt'\n",
        "            feature_dic = load_feature_data(matrix_filepath)\n",
        "            #log_name = f'{name}_log'\n",
        "\n",
        "            #load the train and test files using the helper functions\n",
        "            training_data_by_type = load_training_data(file_name + '/train.txt')\n",
        "            valid_true_data_by_edge, valid_false_data_by_edge = load_testing_data(file_name + '/valid.txt')\n",
        "            testing_true_data_by_edge, testing_false_data_by_edge = load_testing_data(file_name + '/test.txt')\n",
        "\n",
        "            #Obtain model outputs and print results\n",
        "            graph_test_scores[name], graph_models[name] = train_model(training_data_by_type, feature_dic, name)\n",
        "            average_auc, average_f1, average_pr = graph_test_scores[name]\n",
        "\n",
        "            print(f'Test Scores for {name} model:')\n",
        "            print(f'AUC: {average_auc}')\n",
        "            print(f'f1: {average_f1}')\n",
        "            print(f'pr: {average_pr}')\n",
        "    else:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BunDFBr1SEpp"
      },
      "outputs": [],
      "source": [
        "if TRAIN_GNN:\n",
        "    graph_embeddings = {}\n",
        "    #Convert \"model\" (the embeddings we're actually after) into their\n",
        "    #concatenated form\n",
        "\n",
        "    for name in graph_models:\n",
        "        embedding_matrix = np.zeros((572, event_num * embedding_dim))\n",
        "\n",
        "        # Process the embeddings\n",
        "        for event_number, drug_embedding in graph_models[name].items():\n",
        "            for drug_num, embedding in drug_embedding.items():\n",
        "                drug_index = int(drug_num)\n",
        "                event_index = int(event_number)\n",
        "                start_index = event_index * embedding_dim\n",
        "                end_index = start_index + embedding_dim\n",
        "                embedding_matrix[drug_index, start_index:end_index] = embedding\n",
        "\n",
        "        graph_embeddings[name] = pd.DataFrame(embedding_matrix)\n",
        "        graph_embeddings[name].to_csv(f'{name}_drug_embedding_matrix.csv', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BzUnqxMutbEi"
      },
      "outputs": [],
      "source": [
        "#save the files locally to run overnight\n",
        "if TRAIN_GNN and DOWNLOAD_MODELS:\n",
        "    for name, df in graph_embeddings.items():\n",
        "        filename = f'{name}_drug_embedding_matrix.csv'\n",
        "        df.to_csv(filename, index=False, header=False)\n",
        "        files.download(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_awkcZJFDWJQ"
      },
      "outputs": [],
      "source": [
        "#Reload created matrices into specified dataframes to remain consistent with other generated output\n",
        "if TRAIN_GNN:\n",
        "    enzyme_df = pd.read_csv('/content/enzyme_drug_embedding_matrix.csv', header=None)\n",
        "    target_df = pd.read_csv('/content/target_drug_embedding_matrix.csv', header=None)\n",
        "    substructure_df = pd.read_csv('/content/substructure_drug_embedding_matrix.csv', header=None)\n",
        "    pathway_df = pd.read_csv('/content/pathway_drug_embedding_matrix.csv', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhkVgnc6C-C4"
      },
      "source": [
        "# OR load pre-calculated graph embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQS_-pHyDBRW",
        "outputId": "5d87b02f-b16f-4813-ba91-9ca48accc798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drug embedding matrices of shape (572, 2080)\n",
            "enzyme_df:\n",
            "       0         1         2         3         4         5         6     \\\n",
            "0 -0.134519  0.072731 -0.115689  0.277850  0.144056 -0.133885  0.308257   \n",
            "1 -0.109487  0.066786 -0.079493  0.308510  0.124736 -0.145775  0.332964   \n",
            "2 -0.132088  0.068527 -0.115999  0.259763  0.158878 -0.143569  0.297094   \n",
            "3 -0.159063  0.096467 -0.104562  0.270554  0.095969 -0.096957  0.346782   \n",
            "4 -0.152987  0.105926 -0.121674  0.257951  0.136562 -0.107454  0.326656   \n",
            "\n",
            "       7         8         9     ...      2070      2071      2072      2073  \\\n",
            "0 -0.310177  0.206568  0.108368  ... -0.124596 -0.228497 -0.173285  0.108145   \n",
            "1 -0.368566  0.170503  0.125484  ... -0.169279 -0.275377 -0.195528  0.198414   \n",
            "2 -0.312255  0.209851  0.109100  ... -0.231555 -0.091012 -0.198595  0.178463   \n",
            "3 -0.288660  0.191809  0.155859  ... -0.196904 -0.088627 -0.151063  0.249412   \n",
            "4 -0.318284  0.189763  0.123710  ... -0.199105 -0.148257 -0.155831  0.144903   \n",
            "\n",
            "       2074      2075      2076      2077      2078      2079  \n",
            "0  0.052556  0.215397  0.232702  0.218229 -0.138810  0.075627  \n",
            "1  0.097195  0.162891  0.159958  0.200088 -0.053234  0.073277  \n",
            "2  0.021500  0.201109  0.208146  0.320981 -0.154805 -0.031278  \n",
            "3  0.062355  0.151784  0.216462  0.306754 -0.119441 -0.087501  \n",
            "4  0.042037  0.161662  0.210805  0.223754 -0.107137 -0.008153  \n",
            "\n",
            "[5 rows x 2080 columns]\n"
          ]
        }
      ],
      "source": [
        "if not TRAIN_GNN:\n",
        "    urls = {}\n",
        "    if USE_GIVEN_DATA:\n",
        "        urls['enzyme_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/enzyme_drug_embedding_matrix.csv'\n",
        "        urls['target_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/target_drug_embedding_matrix.csv'\n",
        "        urls['substructure_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/substructure_drug_embedding_matrix.csv'\n",
        "        urls['pathway_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/pathway_drug_embedding_matrix.csv'\n",
        "    else:\n",
        "        urls['enzyme_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/raw_data_enzyme_drug_embedding_matrix.csv'\n",
        "        urls['target_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/raw_data_target_drug_embedding_matrix.csv'\n",
        "        urls['substructure_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/raw_data_substructure_drug_embedding_matrix.csv'\n",
        "        urls['pathway_embedding_matrix'] = 'https://raw.githubusercontent.com/NealRyan/Drug-drug-interaction-modeling/main/Data/Embedding%20Matrices/raw_data_pathway_drug_embedding_matrix.csv'\n",
        "\n",
        "    embedding_matrices = {}\n",
        "\n",
        "    for key, url in urls.items():\n",
        "        embedding_matrices[key] = pd.read_csv(url, header=None)\n",
        "\n",
        "\n",
        "    enzyme_df = embedding_matrices['enzyme_embedding_matrix']\n",
        "    target_df = embedding_matrices['target_embedding_matrix']\n",
        "    substructure_df = embedding_matrices['substructure_embedding_matrix']\n",
        "    pathway_df = embedding_matrices['pathway_embedding_matrix']\n",
        "\n",
        "    print(f'drug embedding matrices of shape {enzyme_df.shape}')\n",
        "    print('enzyme_df:')\n",
        "    print(enzyme_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7mNBTTWk7cQ"
      },
      "source": [
        "## Model\n",
        "\n",
        "#### Prepare for Neural Network\n",
        "\n",
        "We currently have a 572x2080 drug embedding matrix for each of the four properties we are using to help us predict if two drugs will interact (enzyme, pathway, substructure, and target). For each embedding matrix, we need to take a slice horizontally to represent the drug with all its graph embedded event information (dimension 1x2080). This vector contains all the graph's embedded knowledge for ONE PARTICULAR drug. As this is a drug-drug interaction task, that won't quite be enough, so we now need to combine it with the other drug vector in our drug pair to create the feature vectors for our neural network. We do this by elementwise multiplication of the vectors such that the end result will still be 1x2080.\n",
        "\n",
        "#### Model Architecture\n",
        "\n",
        "Replicating the paper, we will utilize a network with the architecture:\n",
        "\n",
        "| Layer               | Input Dim | Output Dim | Activation Function | Dropout Rate |\n",
        "| --------            | --------- | ---------- | ------------------- | ------------ |\n",
        "| Linear              | 2080      | 512        | ReLU                |              |\n",
        "| Batch Normalization | 512       |            |                     |              |\n",
        "| Dropout             |           |            |                     | 0.3          |\n",
        "| Linear              | 512       | 256        | ReLU                |              |\n",
        "| Batch Normalization | 256       |            |                     |              |\n",
        "| Dropout             |           |            |                     | 0.3          |\n",
        "| Linear              | 256       | 65         |                     |              |\n",
        "\n",
        "\n",
        "Separate networks will be instantiated for each of the four features, and each network outputs a probability vector across the 66 different interactions. We then take the average of the four vectors to obtain the final probability vector (with values from 0-1) of dimensions 1x66 (65+1, where the first index is for no interaction, and the other indices represent a reaction at that event_num+1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "phEzhS_4xjKG"
      },
      "outputs": [],
      "source": [
        "#Dataset for training cases\n",
        "class DrugInteractionDataset(Dataset):\n",
        "    def __init__(self, df, matrix):\n",
        "        self.matrix = torch.tensor(matrix.values, dtype=torch.float32)\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        drug1_idx, drug2_idx, event_number = int(row['drug1']), int(row['drug2']), int(row['event_num'])\n",
        "\n",
        "        #Create feature vector from the embeddings\n",
        "        feature_vector = self.matrix[drug1_idx] * self.matrix[drug2_idx]\n",
        "\n",
        "        #Create label tensor with a 1 at the index of event_num+1\n",
        "        #Where a label at 0 indicates no interaction\n",
        "        label = torch.zeros((event_num+1,), dtype=torch.float32)\n",
        "        label[event_number+1] = 1.0\n",
        "\n",
        "        return feature_vector, label\n",
        "\n",
        "#Dataset for test cases\n",
        "class TestInteractionDataset(Dataset):\n",
        "    def __init__(self, df, enzyme_matrix, target_matrix, substructure_matrix, pathway_matrix):\n",
        "        self.df = df\n",
        "        self.enzyme_matrix = torch.tensor(enzyme_matrix.values, dtype=torch.float32)\n",
        "        self.target_matrix = torch.tensor(target_matrix.values, dtype=torch.float32)\n",
        "        self.substructure_matrix = torch.tensor(substructure_matrix.values, dtype=torch.float32)\n",
        "        self.pathway_matrix = torch.tensor(pathway_matrix.values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        drug1_idx, drug2_idx, event_number, interaction = (\n",
        "            int(row['drug1']),\n",
        "            int(row['drug2']),\n",
        "            int(row['event_num']),\n",
        "            int(row['interaction'])\n",
        "        )\n",
        "\n",
        "        # Create feature vectors from the embeddings\n",
        "        enzyme_feature_vector = self.enzyme_matrix[drug1_idx] * self.enzyme_matrix[drug2_idx]\n",
        "        target_feature_vector = self.target_matrix[drug1_idx] * self.target_matrix[drug2_idx]\n",
        "        substructure_feature_vector = self.substructure_matrix[drug1_idx] * self.substructure_matrix[drug2_idx]\n",
        "        pathway_feature_vector = self.pathway_matrix[drug1_idx] * self.pathway_matrix[drug2_idx]\n",
        "\n",
        "        #Create label tensor as a 66-dimensional zero tensor\n",
        "        #65+1 to include the no reaction case\n",
        "        label = torch.zeros(event_num+1, dtype=torch.float32)\n",
        "        # Set to 1 at the event_num index if interaction is 1\n",
        "        if interaction == 1:\n",
        "            label[event_number+1] = 1.0\n",
        "        else:\n",
        "            label[0] = 1.0\n",
        "\n",
        "        return (enzyme_feature_vector,\n",
        "                target_feature_vector,\n",
        "                substructure_feature_vector,\n",
        "                pathway_feature_vector), label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-apZNp8k7cQ"
      },
      "source": [
        "#### Data loaders: Dense Neural Network\n",
        "\n",
        "As the neural network outputs a 1x66 dimensional output vectors (that represent interaction or not over 65 event types with one dimension to predict no interaction), the labels will also need to be 66 dim vectors.\n",
        "\n",
        "The logic for training data is to just make a zeros tensor and one-hot encode the tensor at the event_num+1 in the training data\n",
        "\n",
        "The logic for testing data is very similar to training. We start with zeros tensors for each of the four matrices (as the test will combine the output of all four models). If interaction = 1 we then one-hot encode at the index of event_num+1. All four tensors are then passed back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_jn3obatIgcU"
      },
      "outputs": [],
      "source": [
        "nn_batch_size = 128\n",
        "\n",
        "test_dataset = TestInteractionDataset(test_df, enzyme_df, target_df, substructure_df, pathway_df)\n",
        "\n",
        "# Data loaders\n",
        "enzyme_train_loader = DataLoader(DrugInteractionDataset(train_df, enzyme_df), batch_size=nn_batch_size, shuffle=True)\n",
        "target_train_loader = DataLoader(DrugInteractionDataset(train_df, target_df), batch_size=nn_batch_size, shuffle=True)\n",
        "substructure_train_loader = DataLoader(DrugInteractionDataset(train_df, substructure_df), batch_size=nn_batch_size, shuffle=True)\n",
        "pathway_train_loader = DataLoader(DrugInteractionDataset(train_df, pathway_df), batch_size=nn_batch_size, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=nn_batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model Implementation"
      ],
      "metadata": {
        "id": "AIQx67fr5YI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LeH3-GwoPj5y"
      },
      "outputs": [],
      "source": [
        "layer_1_dim = 512  #Default 512\n",
        "layer_2_dim = 256 #Default 256\n",
        "input_dim = embedding_dim * event_num # DO NOT CHANGE\n",
        "output_dim = event_num+1 # DO NOT CHANGE\n",
        "dropout = 0.3 #Default 0.3\n",
        "learning_rate = 0.001 #Default 0.001 in Keras (what the paper uses)\n",
        "num_epochs = 100 #Default 100\n",
        "patience = 10 #Default 10\n",
        "cross_fold_value = 5 #Default 5\n",
        "state = 0 #random state for cross fold validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "N35HQe2eOV8p"
      },
      "outputs": [],
      "source": [
        "class DrugInteractionNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DrugInteractionNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, layer_1_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=layer_1_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc2 = nn.Linear(layer_1_dim, layer_2_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(num_features=layer_2_dim)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc3 = nn.Linear(layer_2_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        #x = F.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "#### Training Objectives\n",
        "\n",
        "We will be using an Adam optimizer, due to it's robustness against untuned hyperparameters (as the paper doesn't tune parameters extensively). We will use a learning rate of *0.001*, optimizing CrossEntropyLoss as this is a multi-class problem.\n",
        "\n",
        "We will be using 5-cross-fold validation.\n",
        "\n",
        "#### Model Pretraining / Computation Requirements\n",
        "\n",
        "Since we are training four separate models, we have pretrained these models and stored in our Github. Based on the notebook configuration (at the top of this notebook), models may be pulled from Github or trainned locally.\n",
        "\n",
        "If you do opt to train, we recommend using an NVIDIA A10G GPU, which takes roughly 7 minutes per epoch (~105 iterations/s with batch size 128). It will take a maximum ~12hrs to complete a full training iteration of up to 100 epochs. The paper employs early stopping to prevent overfitting, so 100 epochs is an upper bound on training time.\n"
      ],
      "metadata": {
        "id": "ONUWOgMtuJuq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "f71G2ob71cq8"
      },
      "outputs": [],
      "source": [
        "enzyme_model = DrugInteractionNetwork(input_dim, output_dim).to(device)\n",
        "target_model = DrugInteractionNetwork(input_dim, output_dim).to(device)\n",
        "substructure_model = DrugInteractionNetwork(input_dim, output_dim).to(device)\n",
        "pathway_model = DrugInteractionNetwork(input_dim, output_dim).to(device)\n",
        "\n",
        "enzyme_optimizer = optim.Adam(enzyme_model.parameters(), lr=learning_rate)\n",
        "target_optimizer = optim.Adam(target_model.parameters(), lr=learning_rate)\n",
        "substructure_optimizer = optim.Adam(substructure_model.parameters(), lr=learning_rate)\n",
        "pathway_optimizer = optim.Adam(pathway_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#create a dictionary of models and their corresponding data loaders and optimizers to aid in training loop\n",
        "models_loaders_optimizers = {\n",
        "    'enzyme_model': (enzyme_model, enzyme_train_loader, enzyme_optimizer),\n",
        "    'target_model': (target_model, target_train_loader, target_optimizer),\n",
        "    'substructure_model': (substructure_model, substructure_train_loader, substructure_optimizer),\n",
        "    'pathway_model': (pathway_model, pathway_train_loader, pathway_optimizer),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-jLJaKPKQx3V"
      },
      "outputs": [],
      "source": [
        "if TRAIN_DNN:\n",
        "    kfold = KFold(n_splits=cross_fold_value, shuffle=True, random_state=state)\n",
        "\n",
        "    for model_name, (model, train_loader, optimizer) in models_loaders_optimizers.items():\n",
        "        print(f\"Training {model_name} with {cross_fold_value}-fold cross-validation\")\n",
        "\n",
        "        overall_best_loss = float('inf')\n",
        "        overall_best_model_path = f'./{model_name}_best_model.pth'\n",
        "\n",
        "        #split training data into k-folds\n",
        "        for fold, (train_idx, valid_idx) in enumerate(kfold.split(np.arange(len(train_loader.dataset))), 1):\n",
        "            print(f\"Fold {fold}/{cross_fold_value}\")\n",
        "\n",
        "            #create subsets for the current fold's training and validation data\n",
        "            train_subset = torch.utils.data.Subset(train_loader.dataset, train_idx)\n",
        "            valid_subset = torch.utils.data.Subset(train_loader.dataset, valid_idx)\n",
        "\n",
        "            #create data loaders for the current fold's training and validation subsets\n",
        "            train_subset_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "            valid_subset_loader = DataLoader(valid_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "            fold_best_loss = float('inf')\n",
        "            loss_increase_count = 0  # Reset the early stopping count for each fold\n",
        "\n",
        "            #main training loop for the current fold\n",
        "            for epoch in range(num_epochs):\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                for inputs, labels in train_subset_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    train_outputs = model(inputs)\n",
        "\n",
        "                    #convert one hot encoded label to single event_num\n",
        "                    train_label_index = labels.max(dim=1)[1]\n",
        "\n",
        "                    loss = criterion(train_outputs, train_label_index)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "\n",
        "                #calculate validation loss for the current fold and epoch\n",
        "                validation_loss = 0.0\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for inputs, labels in valid_subset_loader:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        validation_outputs = model(inputs)\n",
        "\n",
        "                        #convert one hot encoded label to single event_num\n",
        "                        validation_label_index = labels.max(dim=1)[1]\n",
        "\n",
        "                        validation_loss += criterion(validation_outputs, validation_label_index).item()\n",
        "\n",
        "                validation_loss /= len(valid_subset_loader)\n",
        "                print(f'[{model_name}] Fold {fold}/{cross_fold_value}, Epoch {epoch + 1}/{num_epochs}, Validation Loss: {validation_loss}')\n",
        "\n",
        "                #check for improvement and implement early stopping if needed\n",
        "                if validation_loss < fold_best_loss:\n",
        "                    fold_best_loss = validation_loss\n",
        "                    loss_increase_count = 0  #reset count if there is an improvement\n",
        "                    if fold_best_loss < overall_best_loss:\n",
        "                        overall_best_loss = fold_best_loss\n",
        "                        torch.save(model.state_dict(), overall_best_model_path)\n",
        "                else:\n",
        "                    loss_increase_count += 1  #increase count if no improvement\n",
        "                    if loss_increase_count >= patience:\n",
        "                        print(f'[{model_name}] Fold {fold}, Stopping early at epoch {epoch + 1}')\n",
        "                        break\n",
        "\n",
        "        print(f'Finished Training {model_name} with cross-validation')\n",
        "        print(f'Best model saved to {overall_best_model_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "L662tf0i4tgy"
      },
      "outputs": [],
      "source": [
        "if TRAIN_DNN:\n",
        "    #load the best models found from cross validation\n",
        "    enzyme_model.load_state_dict(torch.load('./enzyme_model_best_model.pth'))\n",
        "    target_model.load_state_dict(torch.load('./target_model_best_model.pth'))\n",
        "    substructure_model.load_state_dict(torch.load('./substructure_model_best_model.pth'))\n",
        "    pathway_model.load_state_dict(torch.load('./pathway_model_best_model.pth'))\n",
        "\n",
        "    #save the files locally to run overnight\n",
        "    if DOWNLOAD_MODELS:\n",
        "      files.download('./enzyme_model_best_model.pth')\n",
        "      files.download('./target_model_best_model.pth')\n",
        "      files.download('./substructure_model_best_model.pth')\n",
        "      files.download('./pathway_model_best_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OR load best trained models"
      ],
      "metadata": {
        "id": "f2Fv8i3tPPD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not TRAIN_DNN:\n",
        "    map_location = 'cpu'\n",
        "\n",
        "    model_paths = {\n",
        "        'enzyme': '/content/enzyme_model_best_model.pth',\n",
        "        'target': '/content/target_model_best_model.pth',\n",
        "        'substructure': '/content/substructure_model_best_model.pth',\n",
        "        'pathway': '/content/pathway_model_best_model.pth',\n",
        "    }\n",
        "\n",
        "    #load the best models found from cross validation\n",
        "    if not USE_GIVEN_DATA:\n",
        "        for key, val in model_paths.items():\n",
        "            model_paths[key] = val.replace('/content/','/content/raw_data_')\n",
        "\n",
        "    enzyme_model.load_state_dict(torch.load(model_paths['enzyme'], map_location=map_location))\n",
        "    target_model.load_state_dict(torch.load(model_paths['target'], map_location=map_location))\n",
        "    substructure_model.load_state_dict(torch.load(model_paths['substructure'], map_location=map_location))\n",
        "    pathway_model.load_state_dict(torch.load(model_paths['pathway'], map_location=map_location))"
      ],
      "metadata": {
        "id": "CqtB4PVsPcPN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6frpLobmk7cR"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "##### Metrics Descriptions\n",
        "\n",
        "The 5 main metrics of accuracy, precision, recall, f1-score, and ROC AUC were used to evaluate the performance of the model. These are 5 standard performance metrics which, when used together, can give a holistic understanding of the model's performance\n",
        "\n",
        "##### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "y0cjqwQ5J7Lb"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr):\n",
        "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vhrpXuHKy5K"
      },
      "source": [
        "### Test and print metrics and ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1m7BpXfAapF",
        "outputId": "c1a85d5d-1e23-4a53-9cf2-9cf6bb51a6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9168120220045619\n",
            "Precision: 0.9176589113092163\n",
            "Recall: 0.9168120220045619\n",
            "F1 Score: 0.9156332492440433\n",
            "ROC AUC: 0.9987331035216991\n"
          ]
        }
      ],
      "source": [
        "# Set models to evaluation mode\n",
        "enzyme_model.eval()\n",
        "target_model.eval()\n",
        "substructure_model.eval()\n",
        "pathway_model.eval()\n",
        "\n",
        "all_scores = []\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "        enzyme_features, target_features, substructure_features, pathway_features = features\n",
        "\n",
        "        #set feature vectors and send them to the device\n",
        "        enzyme_features = enzyme_features.to(device)\n",
        "        target_features = target_features.to(device)\n",
        "        substructure_features = substructure_features.to(device)\n",
        "        pathway_features = pathway_features.to(device)\n",
        "\n",
        "        #get model outputs\n",
        "        enzyme_outputs = enzyme_model(enzyme_features)\n",
        "        target_outputs = target_model(target_features)\n",
        "        substructure_outputs = substructure_model(substructure_features)\n",
        "        pathway_outputs = pathway_model(pathway_features)\n",
        "\n",
        "        #manually apply softmax to each output\n",
        "        enzyme_outputs = F.softmax(enzyme_model(enzyme_features), dim=1)\n",
        "        target_outputs = F.softmax(target_model(target_features), dim=1)\n",
        "        substructure_outputs = F.softmax(substructure_model(substructure_features), dim=1)\n",
        "        pathway_outputs = F.softmax(pathway_model(pathway_features), dim=1)\n",
        "\n",
        "        #create a simple average of the 4 outputs as in the paper\n",
        "        avg_outputs = (enzyme_outputs + target_outputs + substructure_outputs + pathway_outputs) / 4\n",
        "\n",
        "        #find the max as an interaction prediction\n",
        "        #print(avg_outputs)\n",
        "        _, y_pred = torch.max(avg_outputs, dim=1)\n",
        "        #print(y_pred)\n",
        "\n",
        "        #append metrics to their respective containers\n",
        "        all_scores.append(avg_outputs.cpu())\n",
        "        all_predictions.append(y_pred.cpu())\n",
        "        all_labels.append(labels.max(dim=1)[1].cpu())\n",
        "\n",
        "#concatenate and convert to numpy arrays\n",
        "all_scores_tensor = torch.cat(all_scores, dim=0)\n",
        "all_predictions_tensor = torch.cat(all_predictions, dim=0)\n",
        "all_labels_tensor = torch.cat(all_labels, dim=0)\n",
        "\n",
        "all_scores_np = torch.softmax(all_scores_tensor, dim=1).numpy()\n",
        "all_predictions_np = all_predictions_tensor.numpy()\n",
        "all_labels_np = all_labels_tensor.numpy()\n",
        "\n",
        "#Use label_binarize to one hot encode\n",
        "all_labels_one_hot = label_binarize(all_labels_np, classes=np.arange(event_num+1))\n",
        "\n",
        "#calculate metrics\n",
        "average_type = 'weighted'\n",
        "accuracy = accuracy_score(all_labels_np, all_predictions_np)\n",
        "precision = precision_score(all_labels_np, all_predictions_np, average=average_type, zero_division=0)\n",
        "recall = recall_score(all_labels_np, all_predictions_np, average=average_type, zero_division=0)\n",
        "f1 = f1_score(all_labels_np, all_predictions_np, average=average_type )\n",
        "\n",
        "#ROC\n",
        "roc_auc = roc_auc_score(all_labels_one_hot, all_scores_np, average='micro', multi_class='ovr')\n",
        "\n",
        "#print metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'ROC AUC: {roc_auc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip2FFIYO8mS8"
      },
      "source": [
        "## Inspect Test Outcome\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "TRqgQeHlzZUD",
        "outputId": "77557403-6223-4332-c3f9-747a5c147d37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
        "\n",
        "#labels subplot\n",
        "axs[0].hist(all_labels_np, bins=range(int(min(all_labels_np)), int(max(all_labels_np)) + 2), align='left', color='blue', edgecolor='black')\n",
        "axs[0].set_title('Distribution of Labels')\n",
        "axs[0].set_xlabel('event_num (0 means no interaction)')\n",
        "axs[0].set_ylabel('Frequency')\n",
        "\n",
        "#predictions subplot\n",
        "axs[1].hist(all_predictions_np, bins=range(int(min(all_predictions_np)), int(max(all_predictions_np)) + 2), align='left', color='blue', edgecolor='black')\n",
        "axs[1].set_title('Distribution of Predictions')\n",
        "axs[1].set_xlabel('event_num (0 means no interaction)')\n",
        "axs[1].set_ylabel('Frequency')\n",
        "\n",
        "#prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "#plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "UQJL9r-IPFDT",
        "outputId": "f73d3657-0487-489e-c3f9-7332b3a8eaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC (One vs Rest): 0.9987331035216991\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "roc_auc_ovr = roc_auc_score(all_labels_one_hot, all_scores_np, average='micro', multi_class='ovr')\n",
        "print(f'ROC AUC (One vs Rest): {roc_auc_ovr}')\n",
        "\n",
        "#compute micro-average ROC curve and ROC area for plotting\n",
        "fpr, tpr, _ = roc_curve(all_labels_one_hot.ravel(), all_scores_np.ravel())\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#plot\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j16jWKv3k7cW"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ-2Ivtvs1pX"
      },
      "source": [
        "### Evaluation Results\n",
        "\n",
        "As shown above, we were able to replicate the results of the original experimentation with metrics similar to, and in some cases better than the original papers:\n",
        "\n",
        "| Metric    | Our Score | Papers Score |\n",
        "| --------- | --------- | ------------ |\n",
        "| Accuracy  | 0.9168    | 0.9206       |\n",
        "| Precision | 0.9176    | 0.9204       |\n",
        "| Recall    | 0.9168    | 0.8259       |\n",
        "| F1        | 0.9156    | 0.8579       |\n",
        "| Roc_auc   | 0.9987    | 0.9992       |\n",
        "\n",
        "\n",
        "We attribute our better results to our proper construction of the training and testing data, which now contain an even 50-50 split of positive and negative examples. The original code only trained the networks on positive samples, resulting in a skew towards predicting an interaction. This manifested in a lower Recall and F1 score. By training on both positive and negative samples, our models recognized when interactions DON'T occur, not just when they do. This resulted in significantly higher Recall and F1 scores, at the expense of a minor regression in accuracy and precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJX1_-gnk7cW"
      },
      "source": [
        "### Analyses / Discussion\n",
        "\n",
        "##### Reproducability\n",
        "\n",
        "The paper's experiments as provided in the github repository were reproducible but not correct. The paper inproperly generates it's training data resulting in significant leakage between datasets. There is also a disconnect between the feature matrices used in the code compared to waht is described in the paper. The paper also provides many \"checkpoints\" to skip parts of the code, such as pre-computed embeddings. However, modifications to the code were not easy as the repo was highly disorganized, using many undocumented, complex operations.\n",
        "\n",
        "By rewriting the code in PyTorch, we found we could easily reproduce and modify the experiments by the original authors. The work to re-write in PyTorch was nontrivial, easily being the most difficult sections as we had to:\n",
        "* Digest and understand each line of the code, without documentation\n",
        "* Re-create our training data.\n",
        "* Validate that our PyTorch code matched the results of the original experiments.\n",
        "* Modularize the code to make each component individually runable (via feature/flags)\n",
        "* Extract configuration of the various models\n",
        "\n",
        "Once the code was rewritten in PyTorch, downstream experiments, data processing, and analysis was extremely easy. With data in more reachable formats, we could easily:\n",
        "* Implement more in-depth feature analysis and plotting\n",
        "* Modify the configuration of models for later experimentation\n",
        "\n",
        "### Plans\n",
        "\n",
        "Now that the repository code is re-written in both Pytorch and in a modifiable form, we plan to implement the following components of our report:\n",
        "* The hypotheses described in the Scope of Reproducability section\n",
        "    * Hyperparameter Tuning\n",
        "        * Layer Size\n",
        "        * Number of Dense Layers\n",
        "        * Dropout rate\n",
        "    * Replacing Dropout layers with optimizer weight decay\n",
        "    * Replacing Adam Optimizer with SGD\n",
        "    * Removal of dropout layers entirely\n",
        "    * Removal of early stopping\n",
        "    * Combinging the four feedwork networks into 1\n",
        "\n",
        "\n",
        "We will also attempt to optimize our Pytorch code to improve runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JYHK-M-k7cW"
      },
      "source": [
        "# Citations\n",
        "\n",
        "1. Rohani, N., Eslahchi, C. Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity. Sci Rep 9, 13645 (2019). https://doi.org/10.1038/s41598-019-50121-3\n",
        "\n",
        "2. Lin, Xuan, et al. \"KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction.\" IJCAI. Vol. 380. 2020.\n",
        "\n",
        "3. Al-Rabeah, M.H., Lakizadeh, A. Prediction of drug-drug interaction events using graph neural networks based feature extraction. Sci Rep 12, 15590 (2022). https://doi.org/10.1038/s41598-022-19999-4\n",
        "\n",
        "4. Zhang, C., Lu, Y. & Zang, T. CNN-DDI: a learning-based method for predicting drug–drug interactions using convolution neural networks. BMC Bioinformatics 23 (Suppl 1), 88 (2022). https://doi.org/10.1186/s12859-022-04612-2\n",
        "\n",
        "5. Yifan Deng, Xinran Xu, Yang Qiu, Jingbo Xia, Wen Zhang, Shichao Liu, A multimodal deep learning framework for predicting drug–drug interaction events, Bioinformatics, Volume 36, Issue 15, August 2020, Pages 4316–4322, https://doi.org/10.1093/bioinformatics/btaa501\n",
        "\n",
        "6. Cen, Y. et al. Representation learning for attributed multiplex heterogeneous network. In Proceedings of the 25th ACM SIGKDD\n",
        "International Conference on Knowledge Discovery &amp; Data Mining 1358–1368 (Association for Computing Machinery, 2019)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}